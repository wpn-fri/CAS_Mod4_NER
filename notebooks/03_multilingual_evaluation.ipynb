{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft / Ideas: Multilingual Evaluation\n",
    "\n",
    "## Overview\n",
    "This notebook evaluates the fine-tuned XLM-RoBERTa model on custom text (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "# Hugging Face libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline\n",
    ")\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found trained model at: c:\\Users\\niw\\Documents\\CAS NLP Mod4\\Mod4_Project\\module4-transformers\\notebooks\\..\\models\\litbank-xlm-roberta\n"
     ]
    }
   ],
   "source": [
    "# Configure paths\n",
    "MODEL_PATH = Path(\"../models/litbank-xlm-roberta\")\n",
    "PROCESSED_DATA_PATH = Path(\"../data/processed\")\n",
    "RESULTS_PATH = Path(\"../results\")\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if model exists\n",
    "if not MODEL_PATH.exists():\n",
    "    print(f\"⚠️  Model not found at {MODEL_PATH}\")\n",
    "    print(\"Please run Notebook 2 (Model Training) first to train the model.\")\n",
    "else:\n",
    "    print(f\"✓ Found trained model at: {MODEL_PATH.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Fine-tuned Model\n",
    "\n",
    "Load the XLM-RoBERTa model trained on English LitBank data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from '..\\models\\litbank-xlm-roberta' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model loaded successfully\n",
      "  Model: XLM-RoBERTa fine-tuned on LitBank\n",
      "  Parameters: 277,463,053\n",
      "  Entity types: 7\n",
      "\n",
      "Supported entity types:\n",
      "  - FAC\n",
      "  - GPE\n",
      "  - LOC\n",
      "  - ORG\n",
      "  - PER\n",
      "  - TIME\n",
      "  - VEH\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "print(\"Loading fine-tuned model...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Load label mapping\n",
    "with open(PROCESSED_DATA_PATH / \"label_mapping.json\", 'r') as f:\n",
    "    label_mapping = json.load(f)\n",
    "\n",
    "label2id = label_mapping[\"label2id\"]\n",
    "id2label = {int(k): v for k, v in label_mapping[\"id2label\"].items()}\n",
    "\n",
    "print(f\"\\n✓ Model loaded successfully\")\n",
    "print(f\"  Model: XLM-RoBERTa fine-tuned on LitBank\")\n",
    "print(f\"  Parameters: {model.num_parameters():,}\")\n",
    "print(f\"  Entity types: {len([l for l in label2id if l.startswith('B-')])}\")\n",
    "print(f\"\\nSupported entity types:\")\n",
    "entity_types = sorted(set([l[2:] for l in label2id.keys() if l.startswith('B-')]))\n",
    "for entity_type in entity_types:\n",
    "    print(f\"  - {entity_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create NER Pipeline\n",
    "\n",
    "- Simplifies inference (handles tokenization, prediction, decoding)\n",
    "- Aggregates subword predictions into word-level entities\n",
    "- Provides confidence scores\n",
    "\n",
    "Example test passage from Charles Dickens' *Christmas Carol*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NER pipeline created\n",
      "  Device: CPU\n",
      "\n",
      "Test prediction:\n",
      "  Input: Although they had but that moment left the school behind them, they were now in the busy thoroughfares of a city, where shadowy passengers passed and re-passed; where shadowy carts and coaches battled for the way, and all the strife and tumult of a real city were. It was made plain enough, by the dressing of the shops, that here, too, it was Christmas-time again; but it was evening, and the streets were lighted up. The Ghost stopped at a certain warehouse door, and asked Scrooge if he knew it.\n",
      "\n",
      "  Detected entities:\n",
      "    - the school           → FAC    (confidence: 0.812)\n",
      "    - the busy thoroughfares of → FAC    (confidence: 0.907)\n",
      "    - a city               → GPE    (confidence: 0.868)\n",
      "    - ,                    → FAC    (confidence: 0.543)\n",
      "    - shadowy passengers   → PER    (confidence: 0.962)\n",
      "    - shadowy carts        → VEH    (confidence: 0.508)\n",
      "    - coaches              → VEH    (confidence: 0.497)\n",
      "    - a real city          → GPE    (confidence: 0.851)\n",
      "    - the shops            → FAC    (confidence: 0.942)\n",
      "    - here                 → FAC    (confidence: 0.464)\n",
      "    - the streets          → FAC    (confidence: 0.897)\n",
      "    - The Ghost            → PER    (confidence: 0.825)\n",
      "    - a certain warehouse  → FAC    (confidence: 0.759)\n",
      "    - Scrooge              → PER    (confidence: 0.953)\n"
     ]
    }
   ],
   "source": [
    "# Create NER pipeline\n",
    "ner_pipeline = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",  # Aggregate subwords into entities\n",
    "    device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    ")\n",
    "\n",
    "print(\"✓ NER pipeline created\")\n",
    "print(f\"  Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Test on example sentence\n",
    "test_sentence = \"Although they had but that moment left the school behind them, they were now in the busy thoroughfares of a city, where shadowy passengers passed and re-passed; where shadowy carts and coaches battled for the way, and all the strife and tumult of a real city were. It was made plain enough, by the dressing of the shops, that here, too, it was Christmas-time again; but it was evening, and the streets were lighted up. The Ghost stopped at a certain warehouse door, and asked Scrooge if he knew it.\"\n",
    "print(f\"\\nTest prediction:\")\n",
    "print(f\"  Input: {test_sentence}\")\n",
    "predictions = ner_pipeline(test_sentence)\n",
    "print(f\"\\n  Detected entities:\")\n",
    "for entity in predictions:\n",
    "    print(f\"    - {entity['word']:20s} → {entity['entity_group']:6s} (confidence: {entity['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"line-height: 2.0; font-size: 14px;\">Although they had but that moment left <mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.81)\">the school <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark> behind them, they were now in <mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.91)\">the busy thoroughfares of <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark> <mark style=\"background-color: #dda0dd; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"GPE (0.87)\">a city <sup style=\"font-size: 0.7em; color: #555;\">[GPE]</sup></mark><mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.54)\">, <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark> where <mark style=\"background-color: #ffa07a; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"PER (0.96)\">shadowy passengers <sup style=\"font-size: 0.7em; color: #555;\">[PER]</sup></mark> passed and re-passed; where <mark style=\"background-color: #ffb6c1; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"VEH (0.51)\">shadowy carts <sup style=\"font-size: 0.7em; color: #555;\">[VEH]</sup></mark> and <mark style=\"background-color: #ffb6c1; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"VEH (0.50)\">coaches <sup style=\"font-size: 0.7em; color: #555;\">[VEH]</sup></mark> battled for the way, and all the strife and tumult of <mark style=\"background-color: #dda0dd; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"GPE (0.85)\">a real city <sup style=\"font-size: 0.7em; color: #555;\">[GPE]</sup></mark> were. It was made plain enough, by the dressing of <mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.94)\">the shops <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark>, that <mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.46)\">here <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark>, too, it was Christmas-time again; but it was evening, and <mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.90)\">the streets <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark> were lighted up. <mark style=\"background-color: #ffa07a; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"PER (0.82)\">The Ghost <sup style=\"font-size: 0.7em; color: #555;\">[PER]</sup></mark> stopped at <mark style=\"background-color: #f0e68c; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"FAC (0.76)\">a certain warehouse <sup style=\"font-size: 0.7em; color: #555;\">[FAC]</sup></mark> door, and asked <mark style=\"background-color: #ffa07a; padding: 2px 4px; margin: 0 2px; border-radius: 3px; font-weight: bold;\" title=\"PER (0.95)\">Scrooge <sup style=\"font-size: 0.7em; color: #555;\">[PER]</sup></mark> if he knew it.</div><div style=\"margin-top: 20px; padding: 10px; background-color: #f5f5f5; border-radius: 5px;\"><strong>Entity Types:</strong><br><span style=\"background-color: #ffa07a; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">PER</span> <span style=\"background-color: #87ceeb; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">ORG</span> <span style=\"background-color: #98fb98; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">LOC</span> <span style=\"background-color: #dda0dd; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">GPE</span> <span style=\"background-color: #f0e68c; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">FAC</span> <span style=\"background-color: #ffb6c1; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">VEH</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Color-coded NER visualization\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def display_ner_results(text: str, entities: List[Dict], show_confidence: bool = True):\n",
    "    \"\"\"\n",
    "    Display NER results with color-coded entity tags.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        entities: List of entity predictions from the pipeline\n",
    "        show_confidence: Whether to show confidence scores\n",
    "    \"\"\"\n",
    "    # Define colors for each entity type\n",
    "    entity_colors = {\n",
    "        'PER': '#ffa07a',  # Light salmon\n",
    "        'ORG': '#87ceeb',  # Sky blue\n",
    "        'LOC': '#98fb98',  # Pale green\n",
    "        'GPE': '#dda0dd',  # Plum\n",
    "        'FAC': '#f0e68c',  # Khaki\n",
    "        'VEH': '#ffb6c1',  # Light pink\n",
    "    }\n",
    "    \n",
    "    # Sort entities by their start position\n",
    "    sorted_entities = sorted(entities, key=lambda x: x['start'])\n",
    "    \n",
    "    # Build HTML with highlighted entities\n",
    "    html_parts = []\n",
    "    last_end = 0\n",
    "    \n",
    "    for entity in sorted_entities:\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        entity_text = entity['word']\n",
    "        entity_type = entity['entity_group']\n",
    "        confidence = entity['score']\n",
    "        \n",
    "        # Add text before entity\n",
    "        if start > last_end:\n",
    "            html_parts.append(text[last_end:start])\n",
    "        \n",
    "        # Add highlighted entity\n",
    "        color = entity_colors.get(entity_type, '#d3d3d3')\n",
    "        tooltip = f\"{entity_type}\"\n",
    "        if show_confidence:\n",
    "            tooltip += f\" ({confidence:.2f})\"\n",
    "        \n",
    "        html_parts.append(\n",
    "            f'<mark style=\"background-color: {color}; padding: 2px 4px; '\n",
    "            f'margin: 0 2px; border-radius: 3px; font-weight: bold;\" '\n",
    "            f'title=\"{tooltip}\">'\n",
    "            f'{entity_text} '\n",
    "            f'<sup style=\"font-size: 0.7em; color: #555;\">[{entity_type}]</sup>'\n",
    "            f'</mark>'\n",
    "        )\n",
    "        \n",
    "        last_end = end\n",
    "    \n",
    "    # Add remaining text\n",
    "    if last_end < len(text):\n",
    "        html_parts.append(text[last_end:])\n",
    "    \n",
    "    # Create legend\n",
    "    legend_html = '<div style=\"margin-top: 20px; padding: 10px; background-color: #f5f5f5; border-radius: 5px;\">'\n",
    "    legend_html += '<strong>Entity Types:</strong><br>'\n",
    "    for entity_type, color in entity_colors.items():\n",
    "        legend_html += f'<span style=\"background-color: {color}; padding: 2px 8px; margin: 2px; border-radius: 3px; display: inline-block;\">{entity_type}</span> '\n",
    "    legend_html += '</div>'\n",
    "    \n",
    "    # Combine everything\n",
    "    full_html = f'<div style=\"line-height: 2.0; font-size: 14px;\">{\"\".join(html_parts)}</div>{legend_html}'\n",
    "    \n",
    "    display(HTML(full_html))\n",
    "\n",
    "# Display the test sentence with color-coded entities\n",
    "print(\"NER Results:\")\n",
    "display_ner_results(test_sentence, predictions, show_confidence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
